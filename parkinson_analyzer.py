"""
–û—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—á–∏ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç —Å–∏–º–ø—Ç–æ–º–æ–≤ –±–æ–ª–µ–∑–Ω–∏ –ü–∞—Ä–∫–∏–Ω—Å–æ–Ω–∞
"""
import json
import base64
import io
import numpy as np
import os
import shutil
from datetime import datetime
from typing import Dict, Optional, List, Tuple
import argparse
import sys
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)
if not logger.handlers:
    handler = logging.StreamHandler()
    handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)

try:
    import matplotlib
    matplotlib.use('Agg')  # –ù–µ–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –±—ç–∫–µ–Ω–¥
    import matplotlib.pyplot as plt
    HAS_MATPLOTLIB = True
except ImportError:
    HAS_MATPLOTLIB = False

from audio_processor import AudioProcessor
from feature_extractor import FeatureExtractor
from symptom_analyzer import SymptomAnalyzer


class ParkinsonAnalyzer:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—á–∏ –Ω–∞ —Å–∏–º–ø—Ç–æ–º—ã –ü–î"""
    
    def __init__(self, save_raw_data: bool = True, raw_data_dir: str = "results"):
        self.audio_processor = AudioProcessor(target_sr=16000)
        self.feature_extractor = FeatureExtractor(sample_rate=16000)
        self.symptom_analyzer = SymptomAnalyzer()
        self.save_raw_data = save_raw_data
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
        self.raw_data_dir = os.path.abspath(raw_data_dir)
        # –í—Å–µ–≥–¥–∞ —Å–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –¥–∞–∂–µ –µ—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ
        os.makedirs(self.raw_data_dir, exist_ok=True)
        logger.info(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {self.raw_data_dir} (save_raw_data={save_raw_data})")
    
    def analyze_audio_file(self, file_path: str, save_raw: Optional[bool] = None, result_id: Optional[str] = None) -> Dict:
        """
        –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞
        
        Args:
            file_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É (WAV/MP3)
        
        Returns:
            –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON –æ—Ç—á–µ—Ç
        """
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
            should_save_raw = save_raw if save_raw is not None else self.save_raw_data
            logger.info(f"üîç –û—Ç–ª–∞–¥–∫–∞: should_save_raw={should_save_raw}, save_raw={save_raw}, self.save_raw_data={self.save_raw_data}")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞, –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω
            if result_id is None:
                result_id = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
            
            logger.info(f"üîç –û—Ç–ª–∞–¥–∫–∞: result_id={result_id}, raw_data_dir={self.raw_data_dir}")
            
            raw_data_paths = {}
            result_dir = None
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å
            if should_save_raw:
                result_dir = os.path.join(self.raw_data_dir, result_id)
                try:
                    os.makedirs(result_dir, exist_ok=True)
                    if os.path.exists(result_dir):
                        logger.info(f"‚úÖ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å–æ–∑–¥–∞–Ω–∞: {result_dir}")
                    else:
                        logger.error(f"‚ö†Ô∏è  –û–®–ò–ë–ö–ê: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å–æ–∑–¥–∞–Ω–∞: {result_dir}")
                except Exception as e:
                    logger.error(f"‚ö†Ô∏è  –û–®–ò–ë–ö–ê –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {result_dir}: {e}")
                    result_dir = None
            
            # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ
            audio, sr = self.audio_processor.load_audio(file_path)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞
            if should_save_raw and result_dir:
                try:
                    # –ö–æ–ø–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
                    original_ext = os.path.splitext(file_path)[1] or '.wav'
                    original_path = os.path.join(result_dir, f"original{original_ext}")
                    shutil.copy2(file_path, original_path)
                    if os.path.exists(original_path):
                        raw_data_paths['original_audio'] = original_path
                        logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª: {original_path}")
                    else:
                        logger.error(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–Ω {original_path}")
                except Exception as e:
                    logger.error(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {e}")
            
            # –†–µ–¥—É–∫—Ü–∏—è —à—É–º–∞
            audio_cleaned = self.audio_processor.noise_reduction(audio)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ
            if should_save_raw and result_dir:
                try:
                    import soundfile as sf
                    processed_path = os.path.join(result_dir, "processed_audio.wav")
                    sf.write(processed_path, audio_cleaned, sr)
                    if os.path.exists(processed_path):
                        raw_data_paths['processed_audio'] = processed_path
                        logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∞—É–¥–∏–æ: {processed_path}")
                    else:
                        logger.error(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–Ω {processed_path}")
                except Exception as e:
                    logger.error(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ: {e}")
            
            # –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
            segments = self.audio_processor.segment_utterances(audio_cleaned, sr)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            segment_paths = []
            if should_save_raw and result_dir and len(segments) > 0:
                import soundfile as sf
                segments_dir = os.path.join(result_dir, "segments")
                os.makedirs(segments_dir, exist_ok=True)
                for i, segment in enumerate(segments):
                    segment_path = os.path.join(segments_dir, f"segment_{i:03d}.wav")
                    sf.write(segment_path, segment, sr)
                    segment_paths.append(segment_path)
                raw_data_paths['segments'] = segment_paths
            
            # 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            # –í–ê–ñ–ù–û: –û—Å–Ω–æ–≤–Ω—ã–µ –∞–∫—É—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (jitter, shimmer, HNR, F0) –¥–æ–ª–∂–Ω—ã 
            # –∏–∑–≤–ª–µ–∫–∞—Ç—å—Å—è –∏–∑ –≤—Å–µ–≥–æ —Ñ–∞–π–ª–∞ —Ü–µ–ª–∏–∫–æ–º, –∞ –Ω–µ —É—Å—Ä–µ–¥–Ω—è—Ç—å—Å—è –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º.
            # –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞—Ä—Ç–∏–∫—É–ª—è—Ü–∏–∏ (—Å–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏, –ø–∞—É–∑—ã).
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –≤—Å–µ–≥–æ —Ñ–∞–π–ª–∞
            all_features = self.feature_extractor.extract_all_features(audio_cleaned)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –¥–ª—è –∞—Ä—Ç–∏–∫—É–ª—è—Ü–∏–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            raw_segment_features = []
            if len(segments) > 0:
                segment_features = []
                for i, segment in enumerate(segments):
                    segment_feat = self.feature_extractor.extract_all_features(segment)
                    segment_features.append(segment_feat)
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ã—Ä—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
                    if should_save_raw:
                        raw_segment_features.append({
                            'segment_index': i,
                            'features': segment_feat,
                            'duration_sec': len(segment) / sr
                        })
                
                # –î–ª—è –∞—Ä—Ç–∏–∫—É–ª—è—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                # (—Å–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏, –ø–∞—É–∑—ã - —ç—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∑–∞–≤–∏—Å—è—Ç –æ—Ç —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏)
                if segment_features:
                    segment_avg = self._average_features(segment_features)
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∞—Ä—Ç–∏–∫—É–ª—è—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                    if 'rate_syl_sec' in segment_avg:
                        all_features['rate_syl_sec'] = segment_avg['rate_syl_sec']
                    if 'pause_ratio' in segment_avg:
                        all_features['pause_ratio'] = segment_avg['pause_ratio']
            
            # 3. –ê–Ω–∞–ª–∏–∑ —Å–∏–º–ø—Ç–æ–º–æ–≤
            analysis = self.symptom_analyzer.analyze(all_features)
            
            # 4. –†–∞—Å—á–µ—Ç DSI (Dysphonia Severity Index)
            dsi_result = self._calculate_dsi(all_features)
            
            # 5. –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
            waveform_data = self.audio_processor.get_waveform(audio_cleaned)
            freqs, times, spectrogram = self.audio_processor.get_spectrogram(audio_cleaned, sr)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
            if should_save_raw and result_dir:
                try:
                    import json as json_lib
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º waveform –¥–∞–Ω–Ω—ã–µ
                    waveform_data_file = os.path.join(result_dir, "waveform_data.json")
                    with open(waveform_data_file, 'w', encoding='utf-8') as f:
                        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å–ø–∏—Å–∫–∏
                        amplitude = waveform_data.get('amplitude', [])
                        time_data = waveform_data.get('time', [])
                        if isinstance(amplitude, np.ndarray):
                            amplitude = amplitude.tolist()
                        if isinstance(time_data, np.ndarray):
                            time_data = time_data.tolist()
                        
                        json_lib.dump({
                            'amplitude': amplitude,
                            'time': time_data,
                            'duration': waveform_data.get('duration', 0.0)
                        }, f, ensure_ascii=False, indent=2)
                    if os.path.exists(waveform_data_file):
                        raw_data_paths['waveform_data'] = waveform_data_file
                        logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã waveform –¥–∞–Ω–Ω—ã–µ: {waveform_data_file}")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º spectrogram –¥–∞–Ω–Ω—ã–µ (—Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, —Ç.–∫. –ø–æ–ª–Ω—ã–π —Å–ø–µ–∫—Ç—Ä –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–∏–º)
                    spectrogram_meta_file = os.path.join(result_dir, "spectrogram_meta.json")
                    with open(spectrogram_meta_file, 'w', encoding='utf-8') as f:
                        json_lib.dump({
                            'frequencies_range': [float(freqs.min()), float(freqs.max())],
                            'time_range': [float(times.min()), float(times.max())],
                            'spectrogram_shape': list(spectrogram.shape),
                            'sample_rate': int(sr)
                        }, f, ensure_ascii=False, indent=2)
                    if os.path.exists(spectrogram_meta_file):
                        raw_data_paths['spectrogram_meta'] = spectrogram_meta_file
                        logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã: {spectrogram_meta_file}")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ã—Ä—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                    if raw_segment_features:
                        segment_features_file = os.path.join(result_dir, "segment_features.json")
                        with open(segment_features_file, 'w', encoding='utf-8') as f:
                            json_lib.dump(raw_segment_features, f, ensure_ascii=False, indent=2)
                        if os.path.exists(segment_features_file):
                            raw_data_paths['segment_features'] = segment_features_file
                            logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {segment_features_file}")
                except Exception as e:
                    logger.error(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π: {e}")
                    import traceback
                    traceback.print_exc()
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è base64 –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            try:
                waveform_base64 = self._generate_waveform_base64(audio_cleaned, sr)
                spectrogram_base64 = self._generate_spectrogram_base64(freqs, times, spectrogram)
            except:
                waveform_base64 = None
                spectrogram_base64 = None
            
            # 6. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Ä–∏—Å–∫–µ
            pd_risk_data = analysis.get('pd_risk_data', {})
            risk_probability = pd_risk_data.get('risk_probability', 0.0)
            risk_level = pd_risk_data.get('risk_level', 'Low')
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è MFCC (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
            mfcc_deviation = "normal"
            if len(analysis.get('exceeded_thresholds', [])) >= 3:
                mfcc_deviation = "high"
            elif len(analysis.get('exceeded_thresholds', [])) >= 1:
                mfcc_deviation = "moderate"
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendation = self._generate_recommendation(risk_level, risk_probability, 
                                                          analysis.get('exceeded_thresholds', []),
                                                          all_features)
            
            result = {
                "audio_summary": {
                    "duration_sec": round(len(audio) / sr, 2),
                    "sample_rate": sr,
                    "segments": len(segments)
                },
                "features": {
                    "jitter_percent": round(all_features.get('jitter_percent', 0.0), 2),
                    "shimmer_percent": round(all_features.get('shimmer_percent', 0.0), 2),
                    "hnr_db": round(all_features.get('hnr_db', 0.0), 1),
                    "rate_syl_sec": round(all_features.get('rate_syl_sec', 0.0), 1),
                    "f0_sd_hz": round(all_features.get('f0_sd_hz', 0.0), 1),
                    "f0_mean_hz": round(all_features.get('f0_mean_hz', 0.0), 1),
                    "amplitude_db_variation": round(all_features.get('amplitude_db_variation', 0.0), 1),
                    "pause_ratio": round(all_features.get('pause_ratio', 0.0), 3)
                },
                "dsi": dsi_result,
                "symptom_scores": {
                    **analysis['symptom_scores'],
                    "pd_risk": analysis['pd_risk']  # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                },
                # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
                "risk_probability": round(risk_probability, 3),
                "risk_level": risk_level,
                "key_features": {
                    "jitter": round(all_features.get('jitter_percent', 0.0), 2),
                    "shimmer": round(all_features.get('shimmer_percent', 0.0), 2),
                    "hnr": round(all_features.get('hnr_db', 0.0), 1),
                    "pitch_mean": round(all_features.get('f0_mean_hz', 0.0), 1),
                    "mfcc_deviation": mfcc_deviation
                },
                "recommendation": recommendation,
                "confidence": round(pd_risk_data.get('confidence', 0.0), 3),
                "report": self._add_dsi_to_report(analysis['report'], dsi_result),
                "visuals": {
                    "waveform": waveform_base64 or f"–î–∞–Ω–Ω—ã–µ: {len(waveform_data['amplitude'])} —Ç–æ—á–µ–∫, "
                               f"–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å {waveform_data['duration']:.2f}—Å",
                    "spectrogram": spectrogram_base64 or f"–ß–∞—Å—Ç–æ—Ç—ã: 0-{sr/2:.0f}Hz, "
                                  f"–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–∞–¥—Ä—ã: {len(times)}"
                }
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if should_save_raw:
                if result_dir and raw_data_paths:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª—ã –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
                    existing_files = {}
                    for key, path in raw_data_paths.items():
                        if key == 'segments':
                            # –î–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
                            existing_segments = [p for p in path if os.path.exists(p)]
                            if existing_segments:
                                existing_files['segments'] = existing_segments
                        else:
                            # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
                            if os.path.exists(path):
                                existing_files[key] = path
                    
                    if existing_files:
                        result['raw_data'] = {
                            'result_id': result_id,
                            'data_directory': result_dir,
                            'files': existing_files
                        }
                        saved_files = list(existing_files.keys())
                        if 'segments' in existing_files:
                            saved_files.append(f"segments ({len(existing_files['segments'])} —Ñ–∞–π–ª–æ–≤)")
                        logger.info(f"‚úÖ –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {result_dir}")
                        logger.info(f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {', '.join(saved_files)}")
                    else:
                        logger.warning(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: should_save_raw=True, –Ω–æ –Ω–∏ –æ–¥–∏–Ω —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ result_dir={result_dir}")
                        logger.warning(f"   –û–∂–∏–¥–∞–µ–º—ã–µ —Ñ–∞–π–ª—ã: {list(raw_data_paths.keys())}")
                else:
                    logger.warning(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: should_save_raw=True, –Ω–æ result_dir={result_dir}, raw_data_paths={len(raw_data_paths) if raw_data_paths else 0} —Ñ–∞–π–ª–æ–≤")
                    logger.warning(f"   –û—Ç–ª–∞–¥–∫–∞: result_dir={result_dir}, should_save_raw={should_save_raw}")
                    if not result_dir:
                        logger.error(f"   –û–®–ò–ë–ö–ê: result_dir –Ω–µ —Å–æ–∑–¥–∞–Ω! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {self.raw_data_dir}")
            
            return result
        
        except Exception as e:
            # –í–æ–∑–≤—Ä–∞—Ç –æ—à–∏–±–∫–∏ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ
            return {
                "error": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}",
                "audio_summary": {},
                "features": {},
                "dsi": {},
                "symptom_scores": {},
                "report": [f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"],
                "visuals": {}
            }
    
    def _generate_recommendation(self, risk_level: str, risk_probability: float,
                                exceeded_thresholds: List[str], features: Dict[str, float]) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞
        
        Args:
            risk_level: Low, Medium, High
            risk_probability: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–∏—Å–∫–∞ (0.0-1.0)
            exceeded_thresholds: –°–ø–∏—Å–æ–∫ –ø—Ä–µ–≤—ã—à–µ–Ω–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤
            features: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        
        Returns:
            –¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
        """
        num_exceeded = len(exceeded_thresholds)
        
        if risk_level == "High":
            # –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ - –¥–µ—Ç–∞–ª—å–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
            details = []
            if 'jitter' in exceeded_thresholds:
                jitter_val = features.get('jitter_percent', 0)
                details.append(f"–ø–æ–≤—ã—à–µ–Ω–Ω—ã–π jitter ({jitter_val:.2f}%)")
            if 'shimmer' in exceeded_thresholds:
                shimmer_val = features.get('shimmer_percent', 0)
                details.append(f"–ø–æ–≤—ã—à–µ–Ω–Ω—ã–π shimmer ({shimmer_val:.2f}%)")
            if 'hnr' in exceeded_thresholds:
                hnr_val = features.get('hnr_db', 25)
                details.append(f"—Å–Ω–∏–∂–µ–Ω–Ω—ã–π HNR ({hnr_val:.1f}dB)")
            
            detail_text = "; ".join(details) if details else f"{num_exceeded} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –æ—Ç–∫–ª–æ–Ω–µ–Ω—ã"
            
            return (f"–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –ü–î ({int(risk_probability * 100)}%): {detail_text}. "
                   f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –Ω–µ–≤—Ä–æ–ª–æ–≥–∞, –æ—Ü–µ–Ω–∫–∞ –ø–æ MDS-UPDRS, "
                   f"–ª–æ–≥–æ–ø–µ–¥–∏—á–µ—Å–∫–∞—è —Ç–µ—Ä–∞–ø–∏—è (LSVT LOUD).")
        
        elif risk_level == "Medium":
            return (f"–£–º–µ—Ä–µ–Ω–Ω—ã–π —Ä–∏—Å–∫ –ü–î ({int(risk_probability * 100)}%): "
                   f"–≤—ã—è–≤–ª–µ–Ω–æ {num_exceeded} –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. "
                   f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏–º–ø—Ç–æ–º–æ–≤, –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ 3-6 –º–µ—Å—è—Ü–µ–≤.")
        
        else:  # Low
            if num_exceeded == 0:
                return ("–ù–∏–∑–∫–∏–π —Ä–∏—Å–∫ –ü–î: –∞–∫—É—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –Ω–æ—Ä–º—ã. "
                       "–°–∏–º–ø—Ç–æ–º—ã –ü–î –Ω–µ –≤—ã—è–≤–ª–µ–Ω—ã. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ.")
            else:
                return (f"–ù–∏–∑–∫–∏–π —Ä–∏—Å–∫ –ü–î ({int(risk_probability * 100)}%): "
                       f"–Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è ({num_exceeded} –ø—Ä–∏–∑–Ω–∞–∫). "
                       f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–∏ –ø–æ—è–≤–ª–µ–Ω–∏–∏ —Å–∏–º–ø—Ç–æ–º–æ–≤.")
    
    def _add_dsi_to_report(self, report: List[str], dsi_result: Dict) -> List[str]:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ DSI –≤ –æ—Ç—á–µ—Ç"""
        updated_report = report.copy()
        
        if dsi_result.get('dsi_score') is not None:
            dsi_score = dsi_result['dsi_score']
            dsi_range = dsi_result['dsi_range']
            breakdown = dsi_result.get('dsi_breakdown', {})
            interpretation = dsi_result.get('interpretation', {})
            
            dsi_info = [
                f"\n=== DSI (Dysphonia Severity Index) ===",
                f"DSI Score: {dsi_score} ({dsi_range})",
                f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:",
                f"  - MPT: {breakdown.get('mpt_sec', 0):.2f}—Å ({interpretation.get('mpt_status', 'N/A')})",
                f"  - F0-High: {breakdown.get('f0_high_hz', 0):.1f} –ì—Ü ({interpretation.get('f0_high_status', 'N/A')})",
                f"  - I-Low: {breakdown.get('i_low_db', 0):.1f} –¥–ë ({interpretation.get('i_low_status', 'N/A')})",
                f"  - Jitter: {breakdown.get('jitter_percent', 0):.2f}% ({interpretation.get('jitter_status', 'N/A')})",
                f"–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: {interpretation.get('pd_risk_note', '')}",
                f"DSI –∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å Voice Handicap Index –∏ –∏–¥–µ–∞–ª–µ–Ω –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ç–µ—Ä–∞–ø–∏–∏ (LSVT LOUD)."
            ]
            updated_report.extend(dsi_info)
        elif dsi_result.get('error'):
            updated_report.append(f"\nDSI: {dsi_result.get('error', '–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å')}")
        
        return updated_report
    
    def _calculate_dsi(self, features: Dict[str, float]) -> Dict:
        """
        –†–∞—Å—á–µ—Ç DSI (Dysphonia Severity Index)
        
        –§–æ—Ä–º—É–ª–∞: DSI = 0.13 √ó MPT + 0.0053 √ó F0-High - 0.26 √ó I-Low - 1.18 √ó Jitter(%) + 12.4
        
        –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è (—Å–æ–≥–ª–∞—Å–Ω–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è–º):
        - –û–∫–æ–ª–æ +5: –ù–æ—Ä–º–∞–ª—å–Ω—ã–π –≥–æ–ª–æ—Å (—Å—Ä–µ–¥–Ω–µ–µ –¥–ª—è –∑–¥–æ—Ä–æ–≤—ã—Ö: +3.05, –¥–∏–∞–ø–∞–∑–æ–Ω 2.13-3.98)
        - –û–∫–æ–ª–æ 0: –ü–æ–≥—Ä–∞–Ω–∏—á–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        - –û–∫–æ–ª–æ -5: –¢—è–∂–µ–ª–∞—è –¥–∏—Å—Ñ–æ–Ω–∏—è
        - –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: –£–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ —É—Ö—É–¥—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–æ–ª–æ—Å–∞
        
        –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã:
        - >= 2.0: –ù–æ—Ä–º–∞–ª—å–Ω—ã–π –≥–æ–ª–æ—Å
        - 0‚Ä¶2.0: –õ–µ–≥–∫–∞—è –¥–∏—Å—Ñ–æ–Ω–∏—è
        - -2‚Ä¶0: –£–º–µ—Ä–µ–Ω–Ω–∞—è –¥–∏—Å—Ñ–æ–Ω–∏—è (PD 1-2)
        - < -2: –¢—è–∂–µ–ª–∞—è –¥–∏—Å—Ñ–æ–Ω–∏—è (PD 3-5)
        """
        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            mpt_sec = features.get('mpt_sec', 0.0)
            f0_high_hz = features.get('f0_high_hz', 0.0)
            i_low_db = features.get('i_low_db', 0.0)
            jitter_percent = features.get('jitter_percent', 0.0)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            if mpt_sec == 0.0 or f0_high_hz == 0.0 or i_low_db == 0.0:
                return {
                    "dsi_score": None,
                    "dsi_range": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ DSI",
                    "dsi_breakdown": {
                        "mpt_sec": round(mpt_sec, 2),
                        "f0_high_hz": round(f0_high_hz, 1),
                        "i_low_db": round(i_low_db, 1),
                        "jitter_percent": round(jitter_percent, 2)
                    },
                    "error": "–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ DSI"
                }
            
            # –†–∞—Å—á–µ—Ç DSI –ø–æ —Ñ–æ—Ä–º—É–ª–µ
            dsi_score = (0.13 * mpt_sec + 
                        0.0053 * f0_high_hz - 
                        0.26 * i_low_db - 
                        1.18 * jitter_percent + 
                        12.4)
            
            # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è DSI
            if dsi_score >= 2.0:
                dsi_range = "–ù–æ—Ä–º–∞–ª—å–Ω—ã–π –≥–æ–ª–æ—Å"
                pd_risk_note = "–ù–∏–∑–∫–∏–π —Ä–∏—Å–∫ –ü–î"
            elif dsi_score >= 0.0:
                dsi_range = "–õ–µ–≥–∫–∞—è –¥–∏—Å—Ñ–æ–Ω–∏—è"
                pd_risk_note = "–£–º–µ—Ä–µ–Ω–Ω—ã–π —Ä–∏—Å–∫ –ü–î"
            elif dsi_score >= -2.0:
                dsi_range = "–£–º–µ—Ä–µ–Ω–Ω–∞—è –¥–∏—Å—Ñ–æ–Ω–∏—è (PD —Ä–∏—Å–∫ –≤—ã—Å–æ–∫–∏–π)"
                pd_risk_note = "–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –ü–î (—Å—Ç–∞–¥–∏—è 1-2)"
            else:
                dsi_range = "–¢—è–∂–µ–ª–∞—è –¥–∏—Å—Ñ–æ–Ω–∏—è (PD —Ä–∏—Å–∫ –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π)"
                pd_risk_note = "–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –ü–î (—Å—Ç–∞–¥–∏—è 3-5)"
            
            return {
                "dsi_score": round(dsi_score, 2),
                "dsi_range": dsi_range,
                "dsi_breakdown": {
                    "mpt_sec": round(mpt_sec, 2),
                    "f0_high_hz": round(f0_high_hz, 1),
                    "i_low_db": round(i_low_db, 1),
                    "jitter_percent": round(jitter_percent, 2)
                },
                "interpretation": {
                    "mpt_status": "–ù–∏–∑–∫–∏–π" if mpt_sec < 10 else "–ù–æ—Ä–º–∞–ª—å–Ω—ã–π" if mpt_sec >= 15 else "–°–Ω–∏–∂–µ–Ω",
                    "f0_high_status": "–ù–∏–∑–∫–∏–π" if f0_high_hz < 300 else "–ù–æ—Ä–º–∞–ª—å–Ω—ã–π" if f0_high_hz >= 400 else "–°–Ω–∏–∂–µ–Ω",
                    "i_low_status": "–ü–æ–≤—ã—à–µ–Ω" if i_low_db > 55 else "–ù–æ—Ä–º–∞–ª—å–Ω—ã–π" if i_low_db < 45 else "–ü–æ–≤—ã—à–µ–Ω",
                    "jitter_status": "–í—ã—Å–æ–∫–∏–π" if jitter_percent > 1.5 else "–ù–æ—Ä–º–∞–ª—å–Ω—ã–π" if jitter_percent < 1.0 else "–ü–æ–≤—ã—à–µ–Ω",
                    "pd_risk_note": pd_risk_note
                },
                "formula": "DSI = 0.13 √ó MPT + 0.0053 √ó F0-High - 0.26 √ó I-Low - 1.18 √ó Jitter(%) + 12.4"
            }
            
        except Exception as e:
            return {
                "dsi_score": None,
                "dsi_range": "–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ DSI",
                "dsi_breakdown": {},
                "error": str(e)
            }
    
    def _average_features(self, feature_list: list) -> Dict:
        """–£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤"""
        if not feature_list:
            return {}
        
        averaged = {}
        keys = set()
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–ª—é—á–∏
        for feat in feature_list:
            keys.update(feat.keys())
        
        # –£—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª—é—á—É
        for key in keys:
            values = [feat.get(key, 0) for feat in feature_list if feat.get(key, 0) != 0]
            if values:
                averaged[key] = np.mean(values)
            else:
                averaged[key] = 0.0
        
        return averaged
    
    def _generate_waveform_base64(self, audio: np.ndarray, sr: int) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤–æ–ª–Ω–æ–≤–æ–π —Ñ–æ—Ä–º—ã"""
        if not HAS_MATPLOTLIB:
            return None
        
        try:
            fig, ax = plt.subplots(figsize=(10, 3))
            time_axis = np.linspace(0, len(audio) / sr, len(audio))
            ax.plot(time_axis, audio, linewidth=0.5)
            ax.set_xlabel('–í—Ä–µ–º—è (—Å)')
            ax.set_ylabel('–ê–º–ø–ª–∏—Ç—É–¥–∞')
            ax.set_title('–í–æ–ª–Ω–æ–≤–∞—è —Ñ–æ—Ä–º–∞')
            ax.grid(True, alpha=0.3)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ base64
            buf = io.BytesIO()
            plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
            buf.seek(0)
            img_base64 = base64.b64encode(buf.read()).decode('utf-8')
            plt.close(fig)
            
            return f"data:image/png;base64,{img_base64}"
        except:
            return None
    
    def _generate_spectrogram_base64(self, freqs: np.ndarray, times: np.ndarray, 
                                    spectrogram: np.ndarray) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã"""
        if not HAS_MATPLOTLIB:
            return None
        
        try:
            fig, ax = plt.subplots(figsize=(10, 6))
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–æ 5kHz –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            freq_mask = freqs <= 5000
            spec_to_show = spectrogram[freq_mask, :]
            freqs_to_show = freqs[freq_mask]
            
            im = ax.imshow(spec_to_show, aspect='auto', origin='lower',
                          extent=[times[0], times[-1], freqs_to_show[0], freqs_to_show[-1]],
                          cmap='viridis', interpolation='bilinear')
            ax.set_xlabel('–í—Ä–µ–º—è (—Å)')
            ax.set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞ (Hz)')
            ax.set_title('–°–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞')
            plt.colorbar(im, ax=ax, label='dB')
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ base64
            buf = io.BytesIO()
            plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
            buf.seek(0)
            img_base64 = base64.b64encode(buf.read()).decode('utf-8')
            plt.close(fig)
            
            return f"data:image/png;base64,{img_base64}"
        except:
            return None
    
    def analyze_to_json(self, file_path: str) -> str:
        """
        –ê–Ω–∞–ª–∏–∑ –∏ –≤–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –≤–∏–¥–µ JSON —Å—Ç—Ä–æ–∫–∏
        
        Args:
            file_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
        
        Returns:
            JSON —Å—Ç—Ä–æ–∫–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        result = self.analyze_audio_file(file_path)
        return json.dumps(result, ensure_ascii=False, indent=2)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(
        description='–ê–Ω–∞–ª–∏–∑ —Ä–µ—á–∏ –Ω–∞ —Å–∏–º–ø—Ç–æ–º—ã –±–æ–ª–µ–∑–Ω–∏ –ü–∞—Ä–∫–∏–Ω—Å–æ–Ω–∞'
    )
    parser.add_argument(
        'audio_file',
        type=str,
        help='–ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É (WAV/MP3)'
    )
    parser.add_argument(
        '-o', '--output',
        type=str,
        help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON –æ—Ç—á–µ—Ç–∞ (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –≤—ã–≤–æ–¥ –≤ stdout)'
    )
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ (—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    analyzer = ParkinsonAnalyzer()
    
    # –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞
    try:
        json_result = analyzer.analyze_to_json(args.audio_file)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–ª–∏ –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(json_result)
            print(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {args.output}")
        else:
            print(json_result)
    
    except FileNotFoundError:
        print(json.dumps({
            "error": f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.audio_file}"
        }, ensure_ascii=False), file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(json.dumps({
            "error": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"
        }, ensure_ascii=False), file=sys.stderr)
        sys.exit(1)


if __name__ == '__main__':
    main()